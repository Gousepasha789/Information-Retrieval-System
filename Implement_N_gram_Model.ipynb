{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6SwjmQU8D+FRgik3q5G2r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gousepasha789/Information-Retrieval-System/blob/main/Implement_N_gram_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "# Sample text\n",
        "irs_text = \"\"\"\n",
        "The Internal Revenue Service (IRS) is responsible for tax collection in the United States.\n",
        "It ensures compliance with tax laws and provides guidelines for taxpayers.\n",
        "Taxpayers can claim deductions for education, medical expenses, and mortgage interest.\n",
        "\"\"\"\n",
        "\n",
        "# Function to preprocess the text\n",
        "def preprocess_irs_text(text):\n",
        "    text = text.lower()\n",
        "    text = ''.join([char if char not in string.punctuation or char in [',', '.'] else ' ' for char in text])\n",
        "    text = text.replace('internal revenue service', 'internal_revenue_service')\n",
        "    return text\n",
        "\n",
        "# Preprocessing\n",
        "processed_irs_text = preprocess_irs_text(irs_text)\n",
        "tokens = word_tokenize(processed_irs_text)\n",
        "\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# Function to generate n-grams\n",
        "def generate_ngrams(tokens, n):\n",
        "    return list(nltk.ngrams(tokens, n))\n",
        "\n",
        "# Generating n-grams\n",
        "unigrams = generate_ngrams(tokens, 1)\n",
        "bigrams = generate_ngrams(tokens, 2)\n",
        "trigrams = generate_ngrams(tokens, 3)\n",
        "\n",
        "# Calculating frequency\n",
        "unigram_freq = Counter(unigrams)\n",
        "bigram_freq = Counter(bigrams)\n",
        "trigram_freq = Counter(trigrams)\n",
        "\n",
        "print(\"\\nUnigram Frequencies:\", unigram_freq)\n",
        "print(\"\\nBigram Frequencies:\", bigram_freq)\n",
        "print(\"\\nTrigram Frequencies:\", trigram_freq)\n",
        "\n",
        "# Function to calculate n-gram probability\n",
        "def calculate_ngram_probability(ngram, ngram_freq, n):\n",
        "    ngram = tuple(ngram)\n",
        "    if n == 1:\n",
        "        total = sum(ngram_freq.values())\n",
        "        return ngram_freq[ngram] / total\n",
        "    elif n == 2:\n",
        "        prev_word = ngram[0]\n",
        "        total = sum(count for (word1, word2), count in ngram_freq.items() if word1 == prev_word)\n",
        "        return ngram_freq[ngram] / total if total > 0 else 0\n",
        "    elif n == 3:\n",
        "        prev_words = ngram[:2]\n",
        "        total = sum(count for (word1, word2, word3), count in ngram_freq.items() if (word1, word2) == tuple(prev_words))\n",
        "        return ngram_freq[ngram] / total if total > 0 else 0\n",
        "\n",
        "# Example probability calculation\n",
        "sequence = ['taxpayers', 'can', 'claim']\n",
        "print(\"\\nProbability of trigram:\", calculate_ngram_probability(sequence, trigram_freq, 3))\n",
        "\n",
        "# Function to predict the next word based on trigram frequencies\n",
        "def predict_next_word(context, trigram_freq):\n",
        "    context_tuple = tuple(context)\n",
        "    candidates = [(word, count) for (w1, w2, word), count in trigram_freq.items() if (w1, w2) == context_tuple]\n",
        "\n",
        "    if candidates:\n",
        "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "        return candidates[0][0]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Predicting the next word\n",
        "context = ['taxpayers', 'can']\n",
        "predicted_word = predict_next_word(context, trigram_freq)\n",
        "print(\"\\nPredicted next word:\", predicted_word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaW7G46LhxS_",
        "outputId": "757fde75-dbfb-4d72-ed6b-202255244278"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['the', 'internal_revenue_service', 'irs', 'is', 'responsible', 'for', 'tax', 'collection', 'in', 'the', 'united', 'states', '.', 'it', 'ensures', 'compliance', 'with', 'tax', 'laws', 'and', 'provides', 'guidelines', 'for', 'taxpayers', '.', 'taxpayers', 'can', 'claim', 'deductions', 'for', 'education', ',', 'medical', 'expenses', ',', 'and', 'mortgage', 'interest', '.']\n",
            "\n",
            "Unigram Frequencies: Counter({('for',): 3, ('.',): 3, ('the',): 2, ('tax',): 2, ('and',): 2, ('taxpayers',): 2, (',',): 2, ('internal_revenue_service',): 1, ('irs',): 1, ('is',): 1, ('responsible',): 1, ('collection',): 1, ('in',): 1, ('united',): 1, ('states',): 1, ('it',): 1, ('ensures',): 1, ('compliance',): 1, ('with',): 1, ('laws',): 1, ('provides',): 1, ('guidelines',): 1, ('can',): 1, ('claim',): 1, ('deductions',): 1, ('education',): 1, ('medical',): 1, ('expenses',): 1, ('mortgage',): 1, ('interest',): 1})\n",
            "\n",
            "Bigram Frequencies: Counter({('the', 'internal_revenue_service'): 1, ('internal_revenue_service', 'irs'): 1, ('irs', 'is'): 1, ('is', 'responsible'): 1, ('responsible', 'for'): 1, ('for', 'tax'): 1, ('tax', 'collection'): 1, ('collection', 'in'): 1, ('in', 'the'): 1, ('the', 'united'): 1, ('united', 'states'): 1, ('states', '.'): 1, ('.', 'it'): 1, ('it', 'ensures'): 1, ('ensures', 'compliance'): 1, ('compliance', 'with'): 1, ('with', 'tax'): 1, ('tax', 'laws'): 1, ('laws', 'and'): 1, ('and', 'provides'): 1, ('provides', 'guidelines'): 1, ('guidelines', 'for'): 1, ('for', 'taxpayers'): 1, ('taxpayers', '.'): 1, ('.', 'taxpayers'): 1, ('taxpayers', 'can'): 1, ('can', 'claim'): 1, ('claim', 'deductions'): 1, ('deductions', 'for'): 1, ('for', 'education'): 1, ('education', ','): 1, (',', 'medical'): 1, ('medical', 'expenses'): 1, ('expenses', ','): 1, (',', 'and'): 1, ('and', 'mortgage'): 1, ('mortgage', 'interest'): 1, ('interest', '.'): 1})\n",
            "\n",
            "Trigram Frequencies: Counter({('the', 'internal_revenue_service', 'irs'): 1, ('internal_revenue_service', 'irs', 'is'): 1, ('irs', 'is', 'responsible'): 1, ('is', 'responsible', 'for'): 1, ('responsible', 'for', 'tax'): 1, ('for', 'tax', 'collection'): 1, ('tax', 'collection', 'in'): 1, ('collection', 'in', 'the'): 1, ('in', 'the', 'united'): 1, ('the', 'united', 'states'): 1, ('united', 'states', '.'): 1, ('states', '.', 'it'): 1, ('.', 'it', 'ensures'): 1, ('it', 'ensures', 'compliance'): 1, ('ensures', 'compliance', 'with'): 1, ('compliance', 'with', 'tax'): 1, ('with', 'tax', 'laws'): 1, ('tax', 'laws', 'and'): 1, ('laws', 'and', 'provides'): 1, ('and', 'provides', 'guidelines'): 1, ('provides', 'guidelines', 'for'): 1, ('guidelines', 'for', 'taxpayers'): 1, ('for', 'taxpayers', '.'): 1, ('taxpayers', '.', 'taxpayers'): 1, ('.', 'taxpayers', 'can'): 1, ('taxpayers', 'can', 'claim'): 1, ('can', 'claim', 'deductions'): 1, ('claim', 'deductions', 'for'): 1, ('deductions', 'for', 'education'): 1, ('for', 'education', ','): 1, ('education', ',', 'medical'): 1, (',', 'medical', 'expenses'): 1, ('medical', 'expenses', ','): 1, ('expenses', ',', 'and'): 1, (',', 'and', 'mortgage'): 1, ('and', 'mortgage', 'interest'): 1, ('mortgage', 'interest', '.'): 1})\n",
            "\n",
            "Probability of trigram: 1.0\n",
            "\n",
            "Predicted next word: claim\n"
          ]
        }
      ]
    }
  ]
}